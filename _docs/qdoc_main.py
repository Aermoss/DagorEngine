import sys
import os
import re
from qdoc_parse import parse
from qdoc_render_rst import renderModuleToRst, sectionTitle2
from log import log
import traceback
import json
import argparse
from cfg import read_commented_json, validated_qdox_cfg
from qdoc_make_stub import mkModuleStub
"""
Description:
  inspired by https://github.com/jtackaberry/luadox
TODO:
  - move qdox module to package
  @code etc - members in all, but member can be string line OR leaf or Container
  ?! nested path spec (foo:module/bar:table/baz:class function)

  ? references (collect objects first and add to another objects later)
"""

class pushd:
    def __init__(self, path):
        self.olddir = os.getcwd()
        if path != '':
            os.chdir(os.path.normpath(path))
    def __enter__(self):
        pass
    def __exit__(self, type, value, traceback):
        os.chdir(self.olddir)

autodoc = re.compile("(\/\/\/\s*@[\S]+\s)|(\/\*\*[\b\s])")
to_mulitline = re.compile(r"\.(SquirrelFunc|Func|Bind|Var|SetValue|Const)\(")

def splitByKeywords(line):
  if len(to_mulitline.findall(line)) > 1:
    return to_mulitline.sub(r'\n.\1(', line).splitlines()
  else:
    return [line]

def splitlines(data):
  data = data.splitlines()
  res = []
  for l in data:
    i = l.find("///")
    if i > 0:
      res.extend(splitByKeywords(l[0:i]))
      res.append(l[i:])
    else:
      res.extend(splitByKeywords(l))
  return res

def scan_in_paths(paths, print_parsed=False, parsed_result=None):
  res = parsed_result or {}

  for file_path in paths:
    if not os.path.exists(file_path):
      log.error(f"no'{file_path}' found in {os.getcwd()}")
      continue
    try:
      with open(file_path, "rt", encoding="utf-8") as f:
        data = f.read()
    except UnicodeDecodeError:
      try:
        with open(file_path, "rt", encoding="ISO-8859-1") as f:
          data = f.read()
      except UnicodeDecodeError:
        data = ""
    if not autodoc.search(data):
      print(f"skipping {file_path} - no qdox comments (/// or /** */)")
      continue
    else:
      print(f"parsing {file_path}")
    try:
      res.update(parse(file_path, splitlines(data), parsed_result = res, print_res=print_parsed))
    except Exception as e:
      traceback.print_exc()
      log.error(f"error parsing file {file_path}")
#  json.dumps(res, indent=2)
  return res

def build_docs(data, destination="source/quirrel_modules"):
  files = set()
  if not os.path.exists(destination):
    os.makedirs(destination)
  for moduleName, module in data.items():
    fpath = os.path.join(destination, moduleName+".rst").replace("\\","/")
    try:
      res = renderModuleToRst(module)
      print("writing", fpath)
      with open(fpath, "wt", encoding="utf-8") as f:
        f.write(".. autogenerated\n\n")
        f.write(res)
      files.update([fpath])
    except Exception as e:
      traceback.print_exc()
      log.error(f"error rendering file to rst {fpath}")
      print(json.dumps(module, indent=2))
  return files

main_rst_tmpl = """
{title}
=========================================


Contents:

.. toctree::
   :maxdepth: 4
   :glob:

   {indexes}

"""

module_rst_tmpl = """
{chapter_title}

{chapter_desc}


Contents:

.. toctree::
   :maxdepth: 2
   :glob:

   *

"""

if __name__ == "__main__":
  p = argparse.ArgumentParser(description='qdox')
  p.add_argument('-pr', '--print_parsed_result', action='store_true', default=False,
                 help='Print parsed result in output')
  p.add_argument('-s', '--stubs_out_dir', type=str, default='',
                 help='Print stubs result in specified directory')
  p.add_argument('-n', '--no_rst_output', action='store_true', default=False,
                 help='Skip saving rst files')
  p.add_argument('-t', '--title', action='store', type=str, default='Docs',
                 help='Skip saving rst files')
  p.add_argument('-o', '--outdir', action='store', type=str, default="_docs/source",
                 help='Directory name for rendered files, created if necessary (default ./_docs/source)')
  p.add_argument('-c', '--config', action='store', type=str, default=".qdox",
                 help="\n".join(["Json (with comment supported) config file with settings."
                 "Config should be in following structure\n:"
                 '[ {'
                 '{'
                  '"  paths": ["foo/bar"], //folders or files list, required'
                  '"  doc_chapter": "my_docs", //internal folder path, required'
                  '"  chapter_title": "My Docs", //displayed title, optional'
                  '"  chapter_desc": "This is my docs documentations", //chapter description'
                  '"  extensions": [".cpp"], //list of extensions of files, optional. In cpp we support some bindings automatically'
                  '"  exclude_dirs_re": [], //optional, list of regexps that should full match to exclude dirs in recursive search'
                  '"  exclude_files_re": [], //optional, list of full match regexp to skip files'
                  '"  recursive": true //optional, do recursive search (for folder in paths)'
                  '}'
                  ']'
                 ])
)

  args = p.parse_args()
  print_parsed_result = args.print_parsed_result
  stubs_dir = args.stubs_out_dir
  outdir = args.outdir
  chapters = []
  chapters_indexes = []

  files_generated = set()
  config = validated_qdox_cfg(read_commented_json(args.config))
  config_dir = os.path.dirname(args.config)
  for e in config:
    result = {}
    paths = e["paths"]
    chapter = e["doc_chapter"]
    recursive = e["recursive"]
    chapter_title = e["chapter_title"]
    chapter_desc = e["chapter_desc"]
    extensions = e["extensions"]
    exclude_dirs_re = re.compile("|".join(e["exclude_dirs_re"]))
    exclude_files_re = re.compile("|".join(e["exclude_files_re"]))

    def isFileToBeUsed(file):
      if exclude_files_re.fullmatch(file):
        return False
      for i in extensions:
        if file.endswith(i):
          return True
      return False

    for path_ in paths:
      with pushd(config_dir):
        path = os.path.join(config_dir, path_).replace("\\","/")
        print(f"scanning path {os.getcwd()}/{path}...")
        if not os.path.exists(path):
          log.error(f"UNEXISTING PATH: {os.getcwd()}/{path}")
          continue
        if os.path.isfile(path):
          result.update(scan_in_paths([path], print_parsed=print_parsed_result, parsed_result=result))
        else:
          for root, dirs, files in os.walk(path):
            if not recursive:
              dirs[:] = []
            else:
              dirs[:] = [d for d in dirs if not exclude_dirs_re.fullmatch(d)]
            files = [os.path.join(root,f) for f in files if isFileToBeUsed(f)]
            result.update(scan_in_paths(files, print_parsed=print_parsed_result, parsed_result=result))
    if len(result)==0:
      log.error(f"no result produced for path:\n  {path}")
      continue
    if stubs_dir != "":
      for moduleName, info in result.items():
        stubDir = os.path.join(stubs_dir, chapter)
        stubPath = os.path.join(stubDir, moduleName)
        if not os.path.exists(stubDir):
          os.makedirs(stubDir)
        if os.path.exists(stubPath):
          os.remove(stubPath)
        if mi := mkModuleStub(info):
          with open(stubPath, "wt") as f:
            f.write(mi)
    if not args.no_rst_output:
      files_generated.update(build_docs(result, destination=f"{outdir}/{chapter}"))
      with open(os.path.join(outdir, chapter, "index.rst"), "wt", encoding = "utf-8") as f:
        f.write(module_rst_tmpl.format(chapter_title = sectionTitle2(chapter_title), chapter_desc=chapter_desc))
      chapters_indexes.append(chapter)
      chapters.append(chapter)
  if not args.no_rst_output:
    if len(chapters)==0:
      log.error("no result produced!")
    else:
      with open(os.path.join(outdir, "index.rst"), "wt", encoding = "utf-8") as f:
        f.write(main_rst_tmpl.format(indexes = "\n   ".join([c +"/index.rst" for c in chapters]), title = args.title))
    files_to_delete = set()
    for c in chapters:
      for root, dirs, files in os.walk(outdir):
        dirs[:] = [d for d in dirs if d in chapters]
        for f in files:
          if not f.endswith(".rst"):
            continue
          data = ""
          with open(os.path.join(root, f), "rt", encoding="utf-8") as i:
            data = i.read(len(".. autogenerated"))
          if data.startswith(".. autogenerated"):
            f = os.path.join(root, f).replace("\\","/")
            if f not in files_generated:
              files_to_delete.update([f])
    for f in files_to_delete:
      print(f"removing obsolete {f}")
      os.remove(f)
